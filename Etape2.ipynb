{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Dans le code de cette étape on sépare le code qu'on soumet à la compétition de celui qu'on utilise pour les tests locaux. Commençons par le code qu'on a soumet à la compétition."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82cca995276ccf9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chargement des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e1bb80fda461475"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = np.load('/kaggle/input/classer-le-text/data_train.npy')\n",
    "X_test = np.load('/kaggle/input/classer-le-text/data_test.npy')\n",
    "df = pd.read_csv('/kaggle/input/classer-le-text/label_train.csv')\n",
    "y_train = df['label'].to_numpy()"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mutlinomial Naive Bayes de base"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "567f378f7af5229e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'ID': range(len(y_pred)),\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('predictions3.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c8aa56298cf733c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multinomial Naive Bayes avec TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc220aa3c662ce82"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Application de TF-IDF\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'ID': range(len(y_pred)),\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('predictions4.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22e59e7a30e5c6c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multinomial Naive Bayes avec l'application de SMOTE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ddd65c96d916900"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Application de SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'ID': range(len(y_pred)),\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('predictions5.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb330c29ea71b77e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM linéaire de base"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7a71369b1292841"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(\n",
    "    random_state=42,\n",
    "    max_iter=10000\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'ID': range(len(y_pred)),\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('predictions6.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1bb93eeee3cee47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM linéaire de base avec C"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "785f30335cf6787d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(\n",
    "    random_state=42,\n",
    "    max_iter=10000,\n",
    "    C=1.0\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'ID': range(len(y_pred)),\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('predictions7.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ec21697276ed87e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest de base"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e87421b9e2e726aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,       \n",
    "    max_depth=10,            \n",
    "    min_samples_split=10,    \n",
    "    min_samples_leaf=5,      \n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'ID': range(len(y_pred)),\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('predictions8.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e2b0f4faa41cfb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multinomial NB avec sélection de features par Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830fe50dce6dd2dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': range(len(rf.feature_importances_)),\n",
    "    'importance': rf.feature_importances_\n",
    "})\n",
    "\n",
    "# Sélection des top features \n",
    "n_top_features = 1000\n",
    "top_features = feature_importance.nlargest(n_top_features, 'importance')['feature'].values\n",
    "\n",
    "# Sélection des features pour X_train et X_test\n",
    "X_train_selected = X_train[:, top_features]\n",
    "X_test_selected = X_test[:, top_features]\n",
    "\n",
    "# Entraînement de MultinomialNB sur les features sélectionnées\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "y_pred = nb.predict(X_test_selected)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'ID': range(len(y_pred)),\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('prediction6.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de8896c0ba12221b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maintenant on va mette le code pour tester les modèles localement. Les tests sont fait en utilisant validation croisée."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd004482955a7405"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multinomial Naive Bayes de base"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6c18cbe379c62e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Évaluation avec validation croisée\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Résultats MultinomialNB:\")\n",
    "print(f\"Score F1 macro moyen (CV): {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "167feb81f6b11a6b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multinomial Naive Bayes avec différents alpha"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f7cb09dc4fd1705"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Application de TF-IDF\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Test de différentes valeurs d'alpha\n",
    "alpha_values = [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "    # Calcul du score moyen avec validation croisée\n",
    "    scores = cross_val_score(clf, X_train_tfidf, y_train, cv=5, scoring='f1_macro')\n",
    "    mean_score = scores.mean()\n",
    "    print(f\"Alpha = {alpha}: score moyen = {mean_score:.3f}\")\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"\\nMeilleur alpha: {best_alpha} (score: {best_score:.3f})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f178f80874fe40eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM linéaire de base"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dc1c96cf61daf2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LinearSVC(random_state=42)\n",
    "\n",
    "# Évaluation avec validation croisée\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Scores de validation croisée:\", scores)\n",
    "print(f\"Score moyen: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c76b107b1489e02"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM linéaire optimisé avec C=0.1 et class_weight='balanced'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc86ae772f57d647"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LinearSVC(\n",
    "    max_iter=2000,        \n",
    "    C=0.1,             \n",
    "    class_weight='balanced', \n",
    "    random_state=42,\n",
    "    dual=False         \n",
    ")\n",
    "\n",
    "# Évaluation avec validation croisée\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Scores de validation croisée:\", scores)\n",
    "print(f\"Score moyen: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0c82b0f05feedd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest de base"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd5be1ee20ee66a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,       \n",
    "    random_state=42,\n",
    ")\n",
    "# Évaluation avec validation croisée\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Scores de validation croisée:\", scores)\n",
    "print(f\"Score moyen: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a66fb39bf375065b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest optimisé"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2820bcbb821f39e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,        # Plus d'arbres\n",
    "    max_depth=10,            # Limiter la profondeur\n",
    "    min_samples_split=10,    # Plus d'échantillons par split\n",
    "    min_samples_leaf=5,      # Plus d'échantillons par feuille\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Évaluation avec validation croisée\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Scores de validation croisée:\", scores)\n",
    "print(f\"Score moyen: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "548fff97bfbe1160"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combinaison de MultinomialNB et RandomForest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51919652c961d6f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Création des classifieurs individuels\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Création de l'ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('nb', nb),\n",
    "        ('rf', rf)\n",
    "    ],\n",
    "    voting='soft'  \n",
    ")\n",
    "\n",
    "# Évaluation avec validation croisée\n",
    "scores = cross_val_score(ensemble, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Scores de validation croisée:\", scores)\n",
    "print(f\"Score moyen: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "\n",
    "# Entraînement sur tout le jeu de données\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Matrice de confusion sur l'ensemble d'entraînement\n",
    "y_pred_train = ensemble.predict(X_train)\n",
    "print(\"\\nMatrice de confusion sur l'ensemble d'entraînement:\")\n",
    "print(confusion_matrix(y_train, y_pred_train))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7fd767c52a0fc70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selection de features basée sur RandomForest pour MultinomialNB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4136a6d85c3d1268"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Étape 1: Entraîner Random Forest pour obtenir les importances\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Création du DataFrame des importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': range(len(rf.feature_importances_)),\n",
    "    'importance': rf.feature_importances_\n",
    "})\n",
    "\n",
    "# Sélection des top features\n",
    "n_top_features = 1000 \n",
    "top_features = feature_importance.nlargest(n_top_features, 'importance')['feature'].values\n",
    "\n",
    "# Sélection des features pour X_train et X_test\n",
    "X_train_selected = X_train[:, top_features]\n",
    "X_test_selected = X_test[:, top_features]\n",
    "\n",
    "print(f\"Nombre de features original: {X_train.shape[1]}\")\n",
    "print(f\"Nombre de features sélectionnées: {len(top_features)}\")\n",
    "\n",
    "# Entraînement de MultinomialNB sur les features sélectionnées\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Évaluation avec validation croisée\n",
    "scores = cross_val_score(nb, X_train_selected, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"\\nScores de validation croisée:\", scores)\n",
    "print(f\"Score moyen: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "\n",
    "# Entraînement sur tout le jeu de données\n",
    "nb.fit(X_train_selected, y_train)\n",
    "\n",
    "# Matrice de confusion sur l'ensemble d'entraînement\n",
    "y_pred_train = nb.predict(X_train_selected)\n",
    "print(\"\\nMatrice de confusion sur l'ensemble d'entraînement:\")\n",
    "print(confusion_matrix(y_train, y_pred_train))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d61d1735250a134c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tests différents nombre de features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5404621b08d36974"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Obtenir les importances des features avec Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': range(len(rf.feature_importances_)),\n",
    "    'importance': rf.feature_importances_\n",
    "})\n",
    "\n",
    "# Tester différents nombres de features\n",
    "n_features_list = [500, 1000, 2000, 3000]\n",
    "\n",
    "results = {}\n",
    "for n_features in n_features_list:\n",
    "    print(f\"\\nTest avec {n_features} features:\")\n",
    "    \n",
    "    # Sélection des features\n",
    "    top_features = feature_importance.nlargest(n_features, 'importance')['feature'].values\n",
    "    X_train_selected = X_train[:, top_features]\n",
    "    X_test_selected = X_test[:, top_features]\n",
    "    \n",
    "    # Évaluation avec MultinomialNB\n",
    "    nb = MultinomialNB()\n",
    "    scores = cross_val_score(nb, X_train_selected, y_train, cv=5, scoring='f1_macro')\n",
    "    \n",
    "    print(f\"Scores de validation croisée: {scores}\")\n",
    "    print(f\"Score moyen: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "    \n",
    "    # Entraînement et matrice de confusion\n",
    "    nb.fit(X_train_selected, y_train)\n",
    "    y_pred_train = nb.predict(X_train_selected)\n",
    "    print(\"\\nMatrice de confusion:\")\n",
    "    print(confusion_matrix(y_train, y_pred_train))\n",
    "    \n",
    "    results[n_features] = {\n",
    "        'mean_score': scores.mean(),\n",
    "        'std_score': scores.std(),\n",
    "        'features': top_features\n",
    "    }\n",
    "\n",
    "best_n_features = max(results.items(), key=lambda x: x[1]['mean_score'])[0]\n",
    "print(f\"\\nMeilleur nombre de features: {best_n_features}\")\n",
    "print(f\"Score: {results[best_n_features]['mean_score']:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a68e65c9d3ecd73"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ba3df61c68d220e8"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a697173fb5eb77cd"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "280d873851b46cea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
